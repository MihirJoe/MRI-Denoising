{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# **BME 5710 project instructions**\n",
    "## Instructor -- Rizwan Ahmad (ahmad.46@osu.edu)\n",
    "## BME5710 -- Spring 2024\n",
    "\n",
    "___\n",
    "### Team assignments\n",
    "* You will work in teams of three to complete the project.\n",
    "    * Team 1: Avneesh Pradhan, Ethan Hessick, Chethena Yerramsetty\n",
    "    * Team 2: Joey Rancitelli, Neeraja Mahalingam, Matt Lin\n",
    "    * Team 3: Arian Seighali, Armon Sekhavat, Garrett Herb\n",
    "    * Team 4: Jenna Popko, Mihir Joshi, Dema Alkashkish\n",
    "    * Team 5: Grant Schrieber, Neil Thakkar, Ahmad Madhwala\n",
    "    * Team 6: Ryan Lang, Jake Klausner, Danny Meringolo\n",
    "    * Team 7: Srujan Jaladi, Cole Anderson, Jason Rosario\n",
    "    * Team 8: Ian Campbell, Allison Smith, Wei Fu\n",
    "    * Team 9: Colin Mack, Emily Yu, Muhammad Sultan\n",
    "\n",
    "___\n",
    "### What's provided\n",
    "Through GitHub Classroom, you will be provided a repository, which includes:\n",
    "* `starter_code.ipynb`: This file has some of the pieces, e.g., code to read grayscale images in TIFF format, that you can use as a starting point.\n",
    "* `fontsetting.py`: This Python function is for typesetting text on figures. You may ignore it if you don't use Tex Live.\n",
    "* `report_template.ipynb`: An empty template for the final report.\n",
    "* `train-clean-tif`: A subfolder containing  $m_1 = 52$ clean images, $\\boldsymbol{y}_{\\sf tr}$, for training.\n",
    "* `val-clean-tif`: A subfolder containing $m_2 = 16$ clean images, $\\boldsymbol{y}_{\\sf val}$, for hyperparameter tuning.\n",
    "* `test-clean-tif`: A subfolder containing $m_3 = 16$ clean images, $\\boldsymbol{y}_{\\sf te}$, for testing. This dataset will be provided closer to the submission deadline. So, don't be surprised if this folder is empty when you first clone the repository.\n",
    "\n",
    "*Note:* All images are $256 \\times 256$ in size and stored in 32-bit floating point TIFF format.\n",
    "\n",
    "___\n",
    "### Instructions\n",
    "In this project, you will develop a CNN-based image denoiser for brain MRI. Image denoising is a common problem encountered in my applications, including digital photography, medical imaging, and surveillance systems, where the goal is to remove noise while preserving important details.\n",
    "\n",
    "* Use the $m_1$ training images to train a CNN-based image denoiser. Since you are only given clean images, you will simulate noisy images, $\\{\\boldsymbol{x}^{(i)}_{\\sf tr}\\}_{i=1}^{m_1}$, by adding zero-mean Gaussian noise to $\\{\\boldsymbol{y}^{(i)}_{\\sf tr}\\}_{i=1}^{m_1}$. You can do so dynamically during the training process. See `starter_code.ipynb` for an example. To train the network, you will minimize a loss, e.g., mean square error, between the clean images $\\{\\boldsymbol{y}_{\\sf tr}^{(i)}\\}_{i=1}^{m_1}$ and the denoised images $\\{\\widehat{\\boldsymbol{y}}_{\\sf tr}^{(i)}\\}_{i=1}^{m_1}$ \n",
    "* Use the $m_2$ validation images to fine tune your network. Don't use these images to train the network. Again, to create clean-noisy image pairs, add noise to $\\{\\boldsymbol{y}^{(i)}_{\\sf val}\\}_{i=1}^{m_2}$ go simulate $\\{\\boldsymbol{x}^{(i)}_{\\sf val}\\}_{i=1}^{m_2}$\n",
    "* Once trained, use the $m_3$ test images to evaluate performance in terms of ${\\sf{NMSE}}(\\boldsymbol{y}, \\widehat{\\boldsymbol{y}}) = 20\\log_{10} \\frac{\\|\\boldsymbol{y} - \\widehat{\\boldsymbol{y}}\\|_2}{\\|\\boldsymbol{y}\\|_2}$ and structural similarity index (SSIM). You will compute NMSE using the expression provided here. For SSIM you may use a built-in function. The test images will be provided closer to the submission deadline. So, your focus should be on maximizing the performance on the validation images.\n",
    "* You will add noise to $\\{\\boldsymbol{y}_{\\sf tr}^{(i)}\\}_{i=1}^{m_1}$ and $\\{\\boldsymbol{y}_{\\sf val}^{(i)}\\}_{i=1}^{m_2}$ dynamically, i.e., use a new realization of noise in each iteration. However, for $\\{\\boldsymbol{y}_{\\sf te}^{(i)}\\}_{i=1}^{m_3}$, you will add noise only once after the training and then evaluate the performance. Also, throughout this project, you may assume that the that noise standard deviation $\\sigma$ is $0.1$ and is known.\n",
    "* All the images are already normalized; therefore, further data scaling (e.g., normalization or standardization) is not required.\n",
    "* In the demos, we have been using only training and test datasets and no validation datasets. Here, we have access to the validation dataset as well. Therefore, in this project, validation dataset will take the place of what we have been calling \"test\" in Demos 16, 17, and 18, and the test dataset will serve as an \"unseen\" dataset.\n",
    "\n",
    "___\n",
    "### Deliverables\n",
    "#### `report_final.ipynb`\n",
    "* Submit the completed project report through GitHub Classroom. \n",
    "* Each member of the team will work on a individual report and make a separate submission.\n",
    "* Submission deadline: April 25, 11:59 pm\n",
    "\n",
    "#### `code_final.ipynb`\n",
    "* Make sure your code is standalone, readable, and free of errors when run on a CPU-only workstation. I will run your code to see if the results in the report are reproducible!\n",
    "* Only one member of the team will submit the code on behalf of the entire team.\n",
    "* Submission deadline: April 25, 11:59 pm\n",
    "\n",
    "___\n",
    "### Rubric\n",
    "* `code_final.ipynb` (75%)\n",
    "    * Display a figure that shows training loss as a function of epochs as well as training and validation NMSE as a function of epochs; see Demos 16, 17, or 18. The data to create this figure should be generated during the training process. (5%)\n",
    "    * After training, evaluate the performance of your CNN on training, validation, and test datasets. Your code should display ${\\sf{NMSE}}_{\\sf tr}$, ${\\sf{SSIM}}_{\\sf tr}$, ${\\sf{NMSE}}_{\\sf val}$, ${\\sf{SSIM}}_{\\sf val}$, ${\\sf{NMSE}}_{\\sf te}$ and ${\\sf{SSIM}}_{\\sf te}$. Here, ${\\sf NMSE}_{\\sf te}$, and ${\\sf SSIM}_{\\sf te}$ represent NMSE and SSIM values averaged over $m_3$ test images. Likewise, ${\\sf NMSE}_{\\sf val}$, ${\\sf SSIM}_{\\sf val}$, ${\\sf NMSE}_{\\sf tr}$, and ${\\sf SSIM}_{\\sf tr}$ represents average values from validation and training datasets, respectively. (5%)\n",
    "    * Make sure your denoiser is awesome in terms of NMSE because your earned percentage $= \\min[89 - 5({\\sf{NMSE}}_{\\sf te} + 18.5), 100]$ (65%)\n",
    "* `report_final.ipynb`(25%)\n",
    "    * Drawing of the CNN architecture (6%)\n",
    "    * Features of the CNN and its training (1%)\n",
    "    * Justification of modeling choices (5%)\n",
    "    * Table that provides average NMSE and SSIM values (6%)\n",
    "    * Justification for including SSIM (1%)\n",
    "    * Display an example image and error maps from the test dataset (5%)\n",
    "    * Visual interpretation of the images (1%)\n",
    "    * Note: \n",
    "        * Use the code in `code_final.ipynb` to generate and save figures, and keep the coding in `report_final.ipynb` to a minimum. If your project report contains long snippets of code, you will be docked 5% of the points.\n",
    "        * If your report has a large number of typos and formatting inconsistencies, you will be docked 5% of the points.\n",
    "\n",
    "___\n",
    "### What's allowed and what's not\n",
    "* Use of ChatGPT, Bard, and similar AI models is not allowed, except for \n",
    "    * learning or verifying the syntax\n",
    "* You are allowed to use GitHub Copilot\n",
    "* Copying the code from online repositories is not allowed\n",
    "* You may use [Google Colab](https://colab.google/) or a local GPU to improve the training efficiency, but I should be able to run the final model on a CPU.\n",
    "* You may use [Optuna](https://optuna.org/) or similar frameworks for hyperparameter tuning, but it's use should be described in the final report.\n",
    "\n",
    "___\n",
    "### Mindset while training a DL model\n",
    "To train your DL model, you will try many different options and see what sticks. This process can be exciting and frustrating at the same time. On one hand, you will see your DL tool improve incrementally, but on the other hand, you may find the hyperparameter tuning process frustrating. A bit of frustration is expected, but this exploration does not have to be a directionless, random process. Use intuition and leverage your understanding of basic ML concepts (e.g., over- and underfitting) to navigate. Also, read scientific literature and blogs to see what others have to say about a specific design choice.\n",
    "* Be creative! Think outside the box! Don't be afraid to try some \"crazy\" ideas.\n",
    "* Experiment with different loss functions. Sometimes a composite loss function, e.g., one based on $\\ell_1$ loss and SSIM, can outperform a loss function based on just MSE or $\\ell_1$.\n",
    "* Experiment with the overall architecture of the CNN. UNet and ResNet are two common choices, but they are not the only ones.\n",
    "* Try different activation functions, perhaps something other than ReLU or leaky ReLU.\n",
    "* The number of layers, number of channels, size of kernels, batch normalization, dropout, data augmentation, transfer learning, learning rate, number of epochs, batch size, optimizer, regularization, skip connections, and learning rate scheduling can all have an impact on the performance of a network. The possibilities are endless :-)\n",
    "___\n",
    "*Happy denoising!*\n",
    "\n",
    "*Last updated: March-20-2024, 6:00 pm*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
